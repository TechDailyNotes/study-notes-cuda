{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TechDailyNotes/study-notes-cuda/blob/main/cuda_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJTvS-A3C7O",
        "outputId": "728d01a0-a2e2-44c8-a0ee-a768877b3b5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n-o861t3R9F",
        "outputId": "0d2a4abe-ad0d-4e6d-dd1b-9303969bf751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello from block 0, thread 0\n",
            "Hello from block 0, thread 1\n",
            "Hello from block 1, thread 0\n",
            "Hello from block 1, thread 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello from block %u, thread %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC6e2d8mGnpU"
      },
      "source": [
        "# Chapter 1: Vector Addition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWINbfDD4dM3",
        "outputId": "6b1524b6-1ecf-471c-e844-940c9b32dbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (tid < n) d_c[tid] = d_a[tid] + d_b[tid];\n",
        "}\n",
        "\n",
        "void numInit(int *h_a, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void numCheck(int *h_a, int *h_b, int *h_c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(h_c[i] == h_a[i] + h_b[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = sizeof(int) * n;\n",
        "\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    h_a = (int*) malloc(bytes);\n",
        "    h_b = (int*) malloc(bytes);\n",
        "    h_c = (int*) malloc(bytes);\n",
        "\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    numInit(h_a, n);\n",
        "    numInit(h_b, n);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = 256;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    numCheck(h_a, h_b, h_c, n);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM0UzCtzQ-_F"
      },
      "source": [
        "# Chapter 2: Unified Memory Vector Add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzXvdq5DRBW1",
        "outputId": "92a7a0e9-ff22-413b-8697-bc5ffcf4b07b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (tid < n) c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "\n",
        "void numInit(int *a, int *b, int *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void numCheck(int *a, int *b, int *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(c[i] == a[i] + b[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int id = cudaGetDevice(&id);\n",
        "\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = n * sizeof(int);\n",
        "\n",
        "    int *a, *b, *c;\n",
        "\n",
        "    cudaMallocManaged(&a, bytes);\n",
        "    cudaMallocManaged(&b, bytes);\n",
        "    cudaMallocManaged(&c, bytes);\n",
        "\n",
        "    numInit(a, b, c, n);\n",
        "\n",
        "    int numThreads = 512;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    cudaMemPrefetchAsync(a, bytes, id);\n",
        "    cudaMemPrefetchAsync(b, bytes, id);\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(a, b, c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemPrefetchAsync(c, bytes, cudaCpuDeviceId);\n",
        "\n",
        "    numCheck(a, b, c, n);\n",
        "\n",
        "    cudaFree(a);\n",
        "    cudaFree(b);\n",
        "    cudaFree(c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGkfonA-YzWC"
      },
      "source": [
        "# Chapter 3: Pinned Memory Vector Add"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1JsLrfqYyiK",
        "outputId": "6684af70-fe61-49bc-97b6-73a2127f4986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) d_c[i] = d_a[i] + d_b[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = sizeof(int) * n;\n",
        "\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    cudaMallocHost(&h_a, bytes);\n",
        "    cudaMallocHost(&h_b, bytes);\n",
        "    cudaMallocHost(&h_c, bytes);\n",
        "\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    int numThreads = 256;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(d_a, d_b, d_c, n);\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(h_c[i] == h_a[i] + h_b[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_b);\n",
        "    cudaFreeHost(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfTG6qPJcgD6"
      },
      "source": [
        "# Chapter 4: Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZhx0k2ci8R",
        "outputId": "150652a4-29ef-4c82-f25a-2a04c1a9198f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Completed!\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matMul(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int rowi = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int coli = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (rowi < n && coli < n) {\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            d_c[rowi * n + coli] += d_a[rowi * n + i] * d_b[i * n + coli];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 10;\n",
        "    size_t bytes = sizeof(int) * n * n;\n",
        "\n",
        "    int *h_a = (int*) malloc(bytes);\n",
        "    int *h_b = (int*) malloc(bytes);\n",
        "    int *h_c = (int*) malloc(bytes);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    for (int i = 0; i < n * n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = 16;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    dim3 sizeBlock(numThreads, numThreads);\n",
        "    dim3 sizeGrid(numBlocks, numBlocks);\n",
        "    matMul<<<sizeGrid, sizeBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "    printf(\"CUDA Completed!\\n\");\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            int cExpected = h_c[i * n + j];\n",
        "            int cActual = 0;\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                cActual += h_a[i * n + k] * h_b[k * n + j];\n",
        "            }\n",
        "            assert(cActual == cExpected);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGXXj8xNkm_Q"
      },
      "source": [
        "# Chapter 5: Tiled Cache Matrix Multiplication (C Implementation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRCDu_IykmgT",
        "outputId": "7b220826-5a06-478a-e005-0aa1eb914c95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sizeEdge = 1024\n",
            "sizeBlockEdge = 16\n",
            "sizeGridEdge = 64\n",
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "const int SIZE_BLOCK_EDGE = 1 << 4;\n",
        "\n",
        "__global__ void matmul(int *a, int *b, int *c, int sizeEdge) {\n",
        "    __shared__ int s_a[SIZE_BLOCK_EDGE * SIZE_BLOCK_EDGE];\n",
        "    __shared__ int s_b[SIZE_BLOCK_EDGE * SIZE_BLOCK_EDGE];\n",
        "\n",
        "    int rowi = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int coli = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    int tmp = 0;\n",
        "\n",
        "    for (int wini = 0; wini < sizeEdge; wini += SIZE_BLOCK_EDGE) {\n",
        "        s_a[threadIdx.y * blockDim.x + threadIdx.x] = a[rowi * sizeEdge + threadIdx.x + wini];\n",
        "        s_b[threadIdx.y * blockDim.x + threadIdx.x] = b[(threadIdx.y + wini) * sizeEdge + coli];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int keri = 0; keri < SIZE_BLOCK_EDGE; keri++) {\n",
        "            tmp += s_a[threadIdx.y * blockDim.x + keri] * s_b[keri * blockDim.x + threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    c[rowi * sizeEdge + coli] = tmp;\n",
        "}\n",
        "\n",
        "void verifyResult(int *a, int *b, int *c, int sizeEdge) {\n",
        "    for (int rowi = 0; rowi < sizeEdge; rowi++) {\n",
        "        for (int coli = 0; coli < sizeEdge; coli++) {\n",
        "            int tmp = 0;\n",
        "\n",
        "            for (int keri = 0; keri < sizeEdge; keri++) {\n",
        "                tmp += a[rowi * sizeEdge + keri] * b[keri * sizeEdge + coli];\n",
        "            }\n",
        "\n",
        "            assert(tmp == c[rowi * sizeEdge + coli]);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int sizeEdge = 1 << 10;\n",
        "    int sizeMatrix = sizeEdge * sizeEdge;\n",
        "    size_t numBytes = sizeof(int) * sizeMatrix;\n",
        "\n",
        "    int *h_a = (int*) malloc(numBytes);\n",
        "    int *h_b = (int*) malloc(numBytes);\n",
        "    int *h_c = (int*) malloc(numBytes);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    cudaMalloc(&d_a, numBytes);\n",
        "    cudaMalloc(&d_b, numBytes);\n",
        "    cudaMalloc(&d_c, numBytes);\n",
        "\n",
        "    for (int i = 0; i < sizeMatrix; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, numBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, numBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int sizeBlockEdge = SIZE_BLOCK_EDGE;\n",
        "    int sizeGridEdge = (int) ceil(1.0 * sizeEdge / sizeBlockEdge);\n",
        "\n",
        "    printf(\"sizeEdge = %d\\n\", sizeEdge);\n",
        "    printf(\"sizeBlockEdge = %d\\n\", sizeBlockEdge);\n",
        "    printf(\"sizeGridEdge = %d\\n\", sizeGridEdge);\n",
        "\n",
        "    dim3 dimBlock(sizeBlockEdge, sizeBlockEdge);\n",
        "    dim3 dimGrid(sizeGridEdge, sizeGridEdge);\n",
        "    matmul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, sizeEdge);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, numBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    verifyResult(h_a, h_b, h_c, sizeEdge);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P41qssD4dCzP"
      },
      "source": [
        "## Practice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fzD5G-TdCRJ"
      },
      "outputs": [],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "const int NUM_ROWS = 1 << 8;\n",
        "const int NUM_COLS = 1 << 12;\n",
        "const int NUM_CHANS = 1 << 16;\n",
        "\n",
        "const int SIZE_EDGE_BLOCK = 1 << 4;\n",
        "\n",
        "__global__ void matmul(int *a, int *b, int *c) {\n",
        "    __shared__ int s_a[SIZE_EDGE_BLOCK * SIZE_EDGE_BLOCK];\n",
        "    __shared__ int s_b[SIZE_EDGE_BLOCK * SIZE_EDGE_BLOCK];\n",
        "\n",
        "    int tmp = 0;\n",
        "\n",
        "    int rowi = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int coli = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    for (int wini = 0; wini < NUM_CHANS; wini += SIZE_EDGE_BLOCK) {\n",
        "        s_a[threadIdx.y * blockDim.x + threadIdx.x] = a[rowi * NUM_CHANS + wini + threadIdx.x];\n",
        "        s_b[threadIdx.y * blockDim.x + threadIdx.x] = b[(wini + threadIdx.y) * NUM_COLS + coli];\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int keri = 0; keri < SIZE_EDGE_BLOCK; keri++) {\n",
        "            tmp += s_a[threadIdx.y * blockDim.x + keri] * s_b[keri * blockDim.x + threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    c[rowi * NUM_COLS + coli] = tmp;\n",
        "}\n",
        "\n",
        "void matrixInit(int *m, int sizeMatrix) {\n",
        "    for (int i = 0; i < sizeMatrix; i++) {\n",
        "        m[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrixVerify(int *a, int *b, int *c) {\n",
        "    for (int rowi = 0; rowi < NUM_ROWS; rowi++) {\n",
        "        for (int coli = 0; coli < NUM_COLS; coli++) {\n",
        "            int actual = 0;\n",
        "\n",
        "            for (int chani = 0; chani < NUM_CHANS; chani++) {\n",
        "                actual += a[rowi * NUM_CHANS + chani] * b[chani * NUM_COLS + coli];\n",
        "            }\n",
        "\n",
        "            if (actual != c[rowi * NUM_COLS + coli]) {\n",
        "                printf(\"rowi = %d, coli = %d\", rowi, coli);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int sizeMatrixA = NUM_ROWS * NUM_CHANS;\n",
        "    int sizeMatrixB = NUM_CHANS * NUM_COLS;\n",
        "    int sizeMatrixC = NUM_ROWS * NUM_COLS;\n",
        "\n",
        "    size_t numBytesA = sizeof(int) * sizeMatrixA;\n",
        "    size_t numBytesB = sizeof(int) * sizeMatrixB;\n",
        "    size_t numBytesC = sizeof(int) * sizeMatrixC;\n",
        "\n",
        "    int *h_a = (int*) malloc(numBytesA);\n",
        "    int *h_b = (int*) malloc(numBytesB);\n",
        "    int *h_c = (int*) malloc(numBytesC);\n",
        "\n",
        "    matrixInit(h_a, sizeMatrixA);\n",
        "    matrixInit(h_b, sizeMatrixB);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, numBytesA);\n",
        "    cudaMalloc(&d_b, numBytesB);\n",
        "    cudaMalloc(&d_c, numBytesC);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, numBytesA, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, numBytesB, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numRowsGrid = NUM_ROWS / SIZE_EDGE_BLOCK;\n",
        "    int numColsGrid = NUM_COLS / SIZE_EDGE_BLOCK;\n",
        "\n",
        "    printf(\"numRowsGrid = %d\\n\", numRowsGrid);\n",
        "    printf(\"numColsGrid = %d\\n\", numColsGrid);\n",
        "\n",
        "    dim3 dimGrid(numRowsGrid, numColsGrid);\n",
        "    dim3 dimBlock(SIZE_EDGE_BLOCK, SIZE_EDGE_BLOCK);\n",
        "\n",
        "    matmul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, numBytesC, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    matrixVerify(h_a, h_b, h_c);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWq_4s7FJHsw"
      },
      "source": [
        "# Chapter 5: Tiled Cache Matrix Multiplication (C++ Implementation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeKogdWxIMLv",
        "outputId": "a8a95823-ae79-439d-b273-851a143c7d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <algorithm>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "__global__ void matmul(int *a, int *b, int *c, int sizeEdge) {\n",
        "    // TODO\n",
        "}\n",
        "\n",
        "void arrayCheck(\n",
        "    const std::vector<int>& a, const std::vector<int>& b,\n",
        "    const std::vector<int>& c, const int sizeEdge\n",
        ") {\n",
        "    assert(false);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Step 1: Setup parameters of the matrix multiplication.\n",
        "    int sizeEdge = 1 << 10;\n",
        "    int sizeMatrix = sizeEdge * sizeEdge;\n",
        "    int sizeBytes = sizeof(int) * sizeMatrix;\n",
        "\n",
        "    // Step 2: Init host matrix.\n",
        "    std::vector<int> h_a(sizeMatrix);\n",
        "    std::vector<int> h_b(sizeMatrix);\n",
        "    std::vector<int> h_c(sizeMatrix);\n",
        "\n",
        "    std::generate(h_a.begin(), h_b.end(), [](){return rand() % 100;});\n",
        "    std::generate(h_b.begin(), h_b.end(), [](){return rand() % 100;});\n",
        "\n",
        "    // Step 3: Init device matrix.\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    cudaMalloc(&d_a, sizeBytes);\n",
        "    cudaMalloc(&d_b, sizeBytes);\n",
        "    cudaMalloc(&d_c, sizeBytes);\n",
        "\n",
        "    // Step 4: Launch the kernel function.\n",
        "    cudaMemcpy(d_a, h_a.data(), sizeBytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b.data(), sizeBytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int sizeBlockEdge = 1 << 4;\n",
        "    int sizeGridEdge = (int) ceil(1.0 * sizeEdge / sizeBlockEdge);\n",
        "\n",
        "    dim3 dimBlock(sizeBlockEdge, sizeBlockEdge);\n",
        "    dim3 dimGrid(sizeGridEdge, sizeGridEdge);\n",
        "    matmul<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, sizeEdge);\n",
        "\n",
        "    cudaMemcpy(h_c.data(), d_c, sizeBytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    arrayCheck(h_a, h_b, h_c, sizeEdge);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    std::cout << \"Success!\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMkXNncK7feh8FZlIST+3m7",
      "gpuType": "A100",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
