{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TechDailyNotes/study-notes-cuda/blob/main/cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkJTvS-A3C7O"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n-o861t3R9F",
        "outputId": "52248074-59d3-4429-8988-b3f6c71231e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block: 0, thread: 0\n",
            "Hello from block: 0, thread: 1\n",
            "Hello from block: 1, thread: 0\n",
            "Hello from block: 1, thread: 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWINbfDD4dM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e33e569-b156-4516-e164-d9d4c6f4065a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMPLETED SUCCESSFULLY\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "// This program computes the sum of two vectors of length N\n",
        "// By: Nick from CoffeeBeforeArch\n",
        "\n",
        "#include <algorithm>\n",
        "#include <cassert>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "// __global__ means this is called from the CPU, and runs on the GPU\n",
        "__global__ void vectorAdd(const int *__restrict a, const int *__restrict b,\n",
        "                          int *__restrict c, int N) {\n",
        "  // Calculate global thread ID\n",
        "  int tid = (blockIdx.x * blockDim.x) + threadIdx.x;\n",
        "\n",
        "  // Boundary check\n",
        "  if (tid < N) c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "\n",
        "// Check vector add result\n",
        "void verify_result(std::vector<int> &a, std::vector<int> &b,\n",
        "                   std::vector<int> &c) {\n",
        "  for (int i = 0; i < a.size(); i++) {\n",
        "    assert(c[i] == a[i] + b[i]);\n",
        "  }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  // Array size of 2^16 (65536 elements)\n",
        "  constexpr int N = 1 << 16;\n",
        "  constexpr size_t bytes = sizeof(int) * N;\n",
        "\n",
        "  // Vectors for holding the host-side (CPU-side) data\n",
        "  std::vector<int> a;\n",
        "  a.reserve(N);\n",
        "  std::vector<int> b;\n",
        "  b.reserve(N);\n",
        "  std::vector<int> c;\n",
        "  c.reserve(N);\n",
        "\n",
        "  // Initialize random numbers in each array\n",
        "  for (int i = 0; i < N; i++) {\n",
        "    a.push_back(rand() % 100);\n",
        "    b.push_back(rand() % 100);\n",
        "  }\n",
        "\n",
        "  // Allocate memory on the device\n",
        "  int *d_a, *d_b, *d_c;\n",
        "  cudaMalloc(&d_a, bytes);\n",
        "  cudaMalloc(&d_b, bytes);\n",
        "  cudaMalloc(&d_c, bytes);\n",
        "\n",
        "  // Copy data from the host to the device (CPU -> GPU)\n",
        "  cudaMemcpy(d_a, a.data(), bytes, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, b.data(), bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Threads per CTA (1024)\n",
        "  int NUM_THREADS = 1 << 10;\n",
        "\n",
        "  // CTAs per Grid\n",
        "  // We need to launch at LEAST as many threads as we have elements\n",
        "  // This equation pads an extra CTA to the grid if N cannot evenly be divided\n",
        "  // by NUM_THREADS (e.g. N = 1025, NUM_THREADS = 1024)\n",
        "  int NUM_BLOCKS = (N + NUM_THREADS - 1) / NUM_THREADS;\n",
        "\n",
        "  // Launch the kernel on the GPU\n",
        "  // Kernel calls are asynchronous (the CPU program continues execution after\n",
        "  // call, but no necessarily before the kernel finishes)\n",
        "  vectorAdd<<<NUM_BLOCKS, NUM_THREADS>>>(d_a, d_b, d_c, N);\n",
        "\n",
        "  // Copy sum vector from device to host\n",
        "  // cudaMemcpy is a synchronous operation, and waits for the prior kernel\n",
        "  // launch to complete (both go to the default stream in this case).\n",
        "  // Therefore, this cudaMemcpy acts as both a memcpy and synchronization\n",
        "  // barrier.\n",
        "  cudaMemcpy(c.data(), d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  // Check result for errors\n",
        "  verify_result(a, b, c);\n",
        "\n",
        "  // Free memory on device\n",
        "  cudaFree(d_a);\n",
        "  cudaFree(d_b);\n",
        "  cudaFree(d_c);\n",
        "\n",
        "  std::cout << \"COMPLETED SUCCESSFULLY\\n\";\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMoLus6u7LwlV3F886V3lJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}