{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TechDailyNotes/study-notes-cuda/blob/main/cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkJTvS-A3C7O"
      },
      "outputs": [],
      "source": [
        "!nvcc --version\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n-o861t3R9F",
        "outputId": "88802889-7e89-464e-8f30-a3e8c3a67946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block 0, thread 0\n",
            "Hello from block 0, thread 1\n",
            "Hello from block 1, thread 0\n",
            "Hello from block 1, thread 1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello() {\n",
        "    printf(\"Hello from block %u, thread %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 1: Vector Addition"
      ],
      "metadata": {
        "id": "tC6e2d8mGnpU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "zWINbfDD4dM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeba0f1f-fef8-454d-dcec-eb362fba5797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ],
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (tid < n) d_c[tid] = d_a[tid] + d_b[tid];\n",
        "}\n",
        "\n",
        "void numInit(int *h_a, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "    }\n",
        "}\n",
        "\n",
        "void numCheck(int *h_a, int *h_b, int *h_c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(h_c[i] == h_a[i] + h_b[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = sizeof(int) * n;\n",
        "\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    h_a = (int*) malloc(bytes);\n",
        "    h_b = (int*) malloc(bytes);\n",
        "    h_c = (int*) malloc(bytes);\n",
        "\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    numInit(h_a, n);\n",
        "    numInit(h_b, n);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = 256;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    numCheck(h_a, h_b, h_c, n);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 2: Unified Memory Vector Add"
      ],
      "metadata": {
        "id": "UM0UzCtzQ-_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *a, int *b, int *c, int n) {\n",
        "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (tid < n) c[tid] = a[tid] + b[tid];\n",
        "}\n",
        "\n",
        "void numInit(int *a, int *b, int *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        c[i] = a[i] + b[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "void numCheck(int *a, int *b, int *c, int n) {\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(c[i] == a[i] + b[i]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int id = cudaGetDevice(&id);\n",
        "\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = n * sizeof(int);\n",
        "\n",
        "    int *a, *b, *c;\n",
        "\n",
        "    cudaMallocManaged(&a, bytes);\n",
        "    cudaMallocManaged(&b, bytes);\n",
        "    cudaMallocManaged(&c, bytes);\n",
        "\n",
        "    numInit(a, b, c, n);\n",
        "\n",
        "    int numThreads = 512;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    cudaMemPrefetchAsync(a, bytes, id);\n",
        "    cudaMemPrefetchAsync(b, bytes, id);\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(a, b, c, n);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaMemPrefetchAsync(c, bytes, cudaCpuDeviceId);\n",
        "\n",
        "    numCheck(a, b, c, n);\n",
        "\n",
        "    cudaFree(a);\n",
        "    cudaFree(b);\n",
        "    cudaFree(c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzXvdq5DRBW1",
        "outputId": "c9133996-e2a5-451f-ccba-cdad5769a411"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 3: Pinned Memory Vector Add"
      ],
      "metadata": {
        "id": "hGkfonA-YzWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void vectorAdd(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    if (i < n) d_c[i] = d_a[i] + d_b[i];\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 16;\n",
        "    size_t bytes = sizeof(int) * n;\n",
        "\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "    cudaMallocHost(&h_a, bytes);\n",
        "    cudaMallocHost(&h_b, bytes);\n",
        "    cudaMallocHost(&h_c, bytes);\n",
        "\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    int numThreads = 256;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "    vectorAdd<<<numBlocks, numThreads>>>(d_a, d_b, d_c, n);\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        assert(h_c[i] == h_a[i] + h_b[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_b);\n",
        "    cudaFreeHost(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1JsLrfqYyiK",
        "outputId": "a84cdf4b-41a6-4b1c-c124-844bc7109f50"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 4: Matrix Multiplication"
      ],
      "metadata": {
        "id": "xfTG6qPJcgD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <assert.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void matMul(int *d_a, int *d_b, int *d_c, int n) {\n",
        "    int rowi = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int coli = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (rowi < n && coli < n) {\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            d_c[rowi * n + coli] += d_a[rowi * n + i] * d_b[i * n + coli];\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 10;\n",
        "    size_t bytes = sizeof(int) * n * n;\n",
        "\n",
        "    int *h_a = (int*) malloc(bytes);\n",
        "    int *h_b = (int*) malloc(bytes);\n",
        "    int *h_c = (int*) malloc(bytes);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    for (int i = 0; i < n * n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = 16;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    dim3 sizeBlock(numThreads, numThreads);\n",
        "    dim3 sizeGrid(numBlocks, numBlocks);\n",
        "    matMul<<<sizeGrid, sizeBlock>>>(d_a, d_b, d_c, n);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "    printf(\"CUDA Completed!\\n\");\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            int cExpected = h_c[i * n + j];\n",
        "            int cActual = 0;\n",
        "            for (int k = 0; k < n; k++) {\n",
        "                cActual += h_a[i * n + k] * h_b[k * n + j];\n",
        "            }\n",
        "            assert(cActual == cExpected);\n",
        "        }\n",
        "    }\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    free(h_a);\n",
        "    free(h_b);\n",
        "    free(h_c);\n",
        "\n",
        "    printf(\"Success!\");\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggZhx0k2ci8R",
        "outputId": "1c96cbe2-5a3f-4e37-ea63-6282736fe6be"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Completed!\n",
            "Success!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 5: Tiled Cache Matrix Multiplication"
      ],
      "metadata": {
        "id": "EGXXj8xNkm_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "__global__ void matmul(int *a, int *b, int *c, int n, int numThreads) {\n",
        "    int rowi = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    int coli = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    __shared__ int A[numThreads];\n",
        "    __shared__ int B[numThreads];\n",
        "\n",
        "    int tmp = 0;\n",
        "\n",
        "    for (int k = 0; k < n / numThreads; k++) {\n",
        "        A[blockIdx.y * numThreads + blockIdx.x] = a[rowi * n + k * numThreads + threadIdx.x];\n",
        "        B[blockIdx.y * numThreads + blockIdx.x] = b[(k * numThreads + threadIdx.y)];\n",
        "    }\n",
        "\n",
        "    c[rowi * n + coli] = tmp;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n = 1 << 10;\n",
        "    size_t bytes = sizeof(int) * n * n;\n",
        "\n",
        "    int *h_a, *h_b, *h_c;\n",
        "    cudaMallocHost(&h_a, bytes);\n",
        "    cudaMallocHost(&h_b, bytes);\n",
        "    cudaMallocHost(&h_c, bytes);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    cudaMalloc(&d_a, bytes);\n",
        "    cudaMalloc(&d_b, bytes);\n",
        "    cudaMalloc(&d_c, bytes);\n",
        "\n",
        "    for (int i = 0; i < n * n; i++) {\n",
        "        h_a[i] = rand() % 100;\n",
        "        h_b[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int numThreads = 16;\n",
        "    int numBlocks = (int) ceil(1.0 * n / numThreads);\n",
        "\n",
        "    dim3 sizeGrid(numBlocks, numBlocks);\n",
        "    dim3 sizeBlock(numThreads, numThreads);\n",
        "\n",
        "    matmul<<<sizeGrid, sizeBlock>>>(d_a, d_b, d_c, n, numThreads);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_b);\n",
        "    cudaFreeHost(h_c);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "HRCDu_IykmgT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPPOzGi2xdMfAdyn05TYSoI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}